version: '3.8'

services:
  postgres:
    image: postgres:13
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  airflow-init:
    image: apache/airflow:2.8.3
    depends_on:
      - postgres
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    volumes:
      - ./dags:/opt/airflow/dags
      - ./plugins:/opt/airflow/plugins
    command: >
      bash -c "
      airflow db init &&
      airflow users create --username admin --password admin --firstname Airflow --lastname Admin --role Admin &&
      echo 'Initialization complete!'
      "
    healthcheck:
      test: ["CMD-SHELL", "airflow db check"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s

  airflow-webserver:
    image: apache/airflow:2.8.3
    depends_on:
      - airflow-init
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__WEBSERVER__RBAC=True
    ports:
      - "8080:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./plugins:/opt/airflow/plugins
      - ./config/airflow.cfg:/opt/airflow/airflow.cfg
    command: airflow webserver
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s

  airflow-scheduler:
    image: apache/airflow:2.8.3
    depends_on:
      - airflow-init
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    volumes:
      - ./dags:/opt/airflow/dags
      - ./plugins:/opt/airflow/plugins
      - ./config/airflow.cfg:/opt/airflow/airflow.cfg
    command: airflow scheduler
    healthcheck:
      test: ["CMD-SHELL", "airflow scheduler check"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s

  spark-master:
    image: apache/spark:3.5.1
    ports:
      - "8081:8080" # Spark Master Web UI (default port is 8080 in apache/spark)
      - "7077:7077" # Spark Master
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master # Set the master host name
      - SPARK_MASTER_PORT=7077
    volumes:
      - spark_data:/opt/spark/work
      - ./spark-conf:/opt/spark/conf
      - ./spark-logs:/opt/spark/logs
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.master.Master", "--host", "spark-master", "--port", "7077", "--webui-port", "8080"]

  spark-worker-1:
    image: apache/spark:3.5.1
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
    volumes:
      - spark_data:/opt/spark/work
      - ./spark-conf:/opt/spark/conf
      - ./spark-logs:/opt/spark/logs
    ports:
      - "8082:8081" # Optional: Expose worker UI on a different port
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077"]

  spark-worker-2:
    image: apache/spark:3.5.1
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
    volumes:
      - spark_data:/opt/spark/work
      - ./spark-conf:/opt/spark/conf
      - ./spark-logs:/opt/spark/logs
    ports:
      - "8083:8081" # Optional: Expose worker UI on a different port
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077"]

  spark-worker-3:
    image: apache/spark:3.5.1
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
    volumes:
      - spark_data:/opt/spark/work
      - ./spark-conf:/opt/spark/conf
      - ./spark-logs:/opt/spark/logs
    ports:
      - "8084:8081" # Optional: Expose worker UI on a different port
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077"]

volumes:
  postgres_data:
  spark_data: